# Char-level Language Model на базе рекуррентных нейросетей

Модель реализована на Python 2.x с использованием фреймворка [Keras](https://keras.io/)
для построения нейросети.

## Обучение модели

Обучение реализовано в [char_predictor.py](https://github.com/Koziev/pushkin/blob/master/char_predictor.py).

Для обучения модели необходим текстовый файл (plain text, utf-8). Какую-либо нормализацию
текста выполнять не требуется. Модель сама составит список всех используемых символов.

Путь к текстовому файла прописан в [char_predictor.py](https://github.com/Koziev/pushkin/blob/master/char_predictor.py).
Там же стоит вторая важная настройка - количество сэмплов в обучающем датасете. Чем большое
сэмплов, тем лучше модель будет работать, но время обучения будет расти пропорционально.

В ходе обучения программа сохраняет модельные данные на диске.

Для nb_patterns = 2000000 обучение с использованием GPU NVidia GTX 980 длится примерно 5 часов,
с учетом 5 отбрасываемых эпох до срабатывания early stopping.


## Проверка работы модели в консоли

Консольный генератор текста реализован в [char_generator.py](https://github.com/Koziev/pushkin/blob/master/char_generator.py).
Он загружает модельные данные из файлов, приготовленных в ходе обучения. далее можно вводить 
с клавиатуры цепочку символов (начало фразы), а модель выведет предполагаемое продолжение.
Примерно так:

```
>: поздравляю с новы
поздравляю с новых настоящий собой мо

>: сяду на пенек, съем пиро
сяду на пенек, съем пиров накопления по нее 

>: цветы нужно поливать кажд
цветы нужно поливать каждое серодоразисте так

>: тише, мыши, кот на кры
тише, мыши, кот на крыше и высоких своей т
```



